<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hadoop on Keep Moving</title>
    <link>https://sanghunka.github.io/tags/hadoop/</link>
    <description>Recent content in Hadoop on Keep Moving</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 02 Dec 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://sanghunka.github.io/tags/hadoop/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>MaxOS Hadoop 설치</title>
      <link>https://sanghunka.github.io/2017/12/maxos-hadoop-%EC%84%A4%EC%B9%98/</link>
      <pubDate>Sat, 02 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2017/12/maxos-hadoop-%EC%84%A4%EC%B9%98/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;2.7.3기준으로 작성되어있음.&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>[Intro to Hadoop and MapReduce] Lesson 5 MapReduce Code</title>
      <link>https://sanghunka.github.io/2017/11/intro-to-hadoop-and-mapreduce-lesson-5-mapreduce-code/</link>
      <pubDate>Mon, 06 Nov 2017 13:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/11/intro-to-hadoop-and-mapreduce-lesson-5-mapreduce-code/</guid>
      <description>1. Introduction 2. Quiz: Input Data How to find total sales/store?
 KEY VALUE  time store name cost store name store name cost store name product type  3. Quiz: Defensive Mapper Code # Your task is to make sure that this mapper code does not fail on corrupt data lines, # but instead just ignores them and continues working import sys def mapper(): # read standard input line by line for line in sys.</description>
    </item>
    
    <item>
      <title>[Intro to Hadoop and MapReduce] Lesson 4 Problem set</title>
      <link>https://sanghunka.github.io/2017/11/intro-to-hadoop-and-mapreduce-lesson-4-problem-set/</link>
      <pubDate>Mon, 06 Nov 2017 12:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/11/intro-to-hadoop-and-mapreduce-lesson-4-problem-set/</guid>
      <description>1. Quiz: HDFS Which of the following is true?
HDFS uses a central SAN(storage area network) to hold its data HDFS stores a single copy of all data HDFS replicates all data for reliability To store 100TB of data in a Hadoop cluster you would need 300TB of raw disk space by default  2. Quiz: DataNode Which of the following is true if one of the nodes running the DataNode daemon on the cluster fails?</description>
    </item>
    
    <item>
      <title>[Intro to Hadoop and MapReduce] Lesson 3 HDFS and MapReduce</title>
      <link>https://sanghunka.github.io/2017/11/intro-to-hadoop-and-mapreduce-lesson-3-hdfs-and-mapreduce/</link>
      <pubDate>Mon, 06 Nov 2017 11:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/11/intro-to-hadoop-and-mapreduce-lesson-3-hdfs-and-mapreduce/</guid>
      <description>1. Quiz: HDFS Is there a problem? &amp;gt; https://youtu.be/6F8-cCUbRU8
Network failure Disk failure on DN(datanode) Not all DN used Block sizes differ Disk failure on NN(namenode)  2. Quiz: Data Redundancy Any problem now?(when NN failure)
Data inaccessible &amp;gt; when network failure on NN Data lost forever &amp;gt; when disk failure on NN No problem  3. NameNode Standby The active namenode works before, but the standby can be configured to take over if the active one fails.</description>
    </item>
    
    <item>
      <title>[Intro to Hadoop and MapReduce] Lesson 2 Problem set</title>
      <link>https://sanghunka.github.io/2017/11/intro-to-hadoop-and-mapreduce-lesson-2-problem-set/</link>
      <pubDate>Mon, 06 Nov 2017 10:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/11/intro-to-hadoop-and-mapreduce-lesson-2-problem-set/</guid>
      <description>1. Quiz: Dimensions of Big Data Which of the following are Part of the 3 dimensions of Big Data?
Volume Cost Importance Velocity Source Variety Security Virality  2. Quiz: Volume Volume of Big Data refers to:
Importance of Data Size of data Speed of data generation The differnet data sources  3. Quiz: Hadoop Ecosystem Check all that are true:
Hadoop provides an efficient way of storing data via HDFS Hadoop has a visualization framework called &amp;lsquo;Giraffe&amp;rsquo; You can analyze large datasets using a high-level language called &amp;lsquo;Pig&amp;rsquo; &amp;lsquo;Hive&amp;rsquo; offers a SQL-like language on top of MapReduce The tools in Hadoop&amp;rsquo;s ecosystem are all proprietary, commercial tools  4.</description>
    </item>
    
    <item>
      <title>[Intro to Hadoop and MapReduce] Lesson 1 Big data</title>
      <link>https://sanghunka.github.io/2017/11/intro-to-hadoop-and-mapreduce-lesson-1-big-data/</link>
      <pubDate>Mon, 06 Nov 2017 09:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/11/intro-to-hadoop-and-mapreduce-lesson-1-big-data/</guid>
      <description>1. Introduction You can read more about Big Data in Wikipedia which is also a company that generates and processes huge amounts of data itself.
MapReduce and Apache Hadoop are the technologies we will be talking about more in this course.
2. Data Sources According to IBM: &amp;ldquo;Every day, 2.5 billion gigabytes of high-velocity data are created in a variety of forms, such as social media posts, information gathered in sensors and medical devices, videos and transaction records&amp;rdquo;</description>
    </item>
    
  </channel>
</rss>