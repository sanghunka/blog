<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Engineering on Keep Moving</title>
    <link>https://sanghunka.github.io/tags/data-engineering/</link>
    <description>Recent content in Data Engineering on Keep Moving</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Dec 2017 14:00:00 +0900</lastBuildDate>
    
	<atom:link href="https://sanghunka.github.io/tags/data-engineering/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[airflow] 6. Multi cluster에서 airflow 실행하기</title>
      <link>https://sanghunka.github.io/2017/12/airflow-6.-multi-cluster%EC%97%90%EC%84%9C-airflow-%EC%8B%A4%ED%96%89%ED%95%98%EA%B8%B0/</link>
      <pubDate>Wed, 20 Dec 2017 14:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/12/airflow-6.-multi-cluster%EC%97%90%EC%84%9C-airflow-%EC%8B%A4%ED%96%89%ED%95%98%EA%B8%B0/</guid>
      <description>요약  다루는 내용  분산 인스턴스에서 각각 airflow worker를 실행하고 task를 분산해서 실행하는법 task가 실행될 worker를 명시적으로 지정하는법  테스트 환경  두 개의 Amazon EC2 Instance 사용 1번 Instance에 아래와 같이 셋팅  metadata database(postsgres) rabbitmq airflow webserver airflow worker  2번 Instance에 아래와 같이 셋팅  airflow worker    airflow configuration  1번과 2번 instance에 airflow를 설치한다. dag폴더에 동일한 파일을 넣어준다. dag폴더를 Git repository로 세팅하고 Chef, Puppet, Ansible등으로 동기화 해주는 방법도 있다.</description>
    </item>
    
    <item>
      <title>[airflow] 5. Pyspark sample code on airflow</title>
      <link>https://sanghunka.github.io/2017/12/airflow-5.-pyspark-sample-code-on-airflow/</link>
      <pubDate>Wed, 20 Dec 2017 13:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/12/airflow-5.-pyspark-sample-code-on-airflow/</guid>
      <description>&lt;p&gt;Airflow에서 Pyspark task 실행하기&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[airflow] 5. Pyspark sample code on airflow</title>
      <link>https://sanghunka.github.io/2017/12/airflow-5.-pyspark-sample-code-on-airflow/</link>
      <pubDate>Wed, 20 Dec 2017 13:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/12/airflow-5.-pyspark-sample-code-on-airflow/</guid>
      <description>&lt;p&gt;Airflow에서 Pyspark task 실행하기&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[airflow] 4. CeleryExecutor 사용하기</title>
      <link>https://sanghunka.github.io/2017/12/airflow-4.-celeryexecutor-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/</link>
      <pubDate>Tue, 05 Dec 2017 17:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/12/airflow-4.-celeryexecutor-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/</guid>
      <description>&lt;p&gt;Airflow CeleryExecutor 사용하기&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[airflow] 3. LocalExecutor 사용하기</title>
      <link>https://sanghunka.github.io/2017/12/airflow-3.-localexecutor-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/</link>
      <pubDate>Tue, 05 Dec 2017 16:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/12/airflow-3.-localexecutor-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/</guid>
      <description>&lt;p&gt;Airflow LocalExecutor 사용하기&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[airflow] 2. 튜토리얼</title>
      <link>https://sanghunka.github.io/2017/11/airflow-2.-%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC/</link>
      <pubDate>Tue, 21 Nov 2017 17:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/11/airflow-2.-%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC/</guid>
      <description>&lt;p&gt;pipeline을 따라 만들어보며 Airflow의 concept, object, usage를 습득하기.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[airflow] 1. 설치</title>
      <link>https://sanghunka.github.io/2017/11/airflow-1.-%EC%84%A4%EC%B9%98/</link>
      <pubDate>Tue, 21 Nov 2017 16:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/11/airflow-1.-%EC%84%A4%EC%B9%98/</guid>
      <description>&lt;p&gt;Airflow 설치하기&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[airflow] 0. Quickstart</title>
      <link>https://sanghunka.github.io/2017/11/airflow-0.-quickstart/</link>
      <pubDate>Tue, 21 Nov 2017 15:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/11/airflow-0.-quickstart/</guid>
      <description># airflow needs a home, ~/airflow is the default, # but you can lay foundation somewhere else if you prefer # (optional) export AIRFLOW_HOME=~/airflow # install from pypi using pip pip install airflow # initialize the database airflow initdb # start the web server, default port is 8080 airflow webserver -p 8080   export AIRFLOW_HOME=~/airflow 명령어로 설치 경로를 지정할 수 있다. AIRFLOW_HOME을 지정하지 않을 경우 default 경로는 ~/airflow 설치는 pip로 간단하게 할 수 있다.</description>
    </item>
    
  </channel>
</rss>