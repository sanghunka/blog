<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Keep Moving</title>
    <link>https://sanghunka.github.io/</link>
    <description>Recent content on Keep Moving</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 22 Jan 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://sanghunka.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>zsh에 설정해둔 alias를 crontab에 사용하고 싶을때</title>
      <link>https://sanghunka.github.io/2018/01/zsh%EC%97%90-%EC%84%A4%EC%A0%95%ED%95%B4%EB%91%94-alias%EB%A5%BC-crontab%EC%97%90-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B3%A0-%EC%8B%B6%EC%9D%84%EB%95%8C/</link>
      <pubDate>Mon, 22 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2018/01/zsh%EC%97%90-%EC%84%A4%EC%A0%95%ED%95%B4%EB%91%94-alias%EB%A5%BC-crontab%EC%97%90-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B3%A0-%EC%8B%B6%EC%9D%84%EB%95%8C/</guid>
      <description>Put your functions in .zshenv.
.zshenv is sourced on all invocations of the shell, unless the -f option is set. It should contain commands to set the command search path, plus other important environment variables. .zshenv should not contain commands that produce output or assume the shell is attached to a tty.
.zshrc is sourced in interactive shells. It should contain commands to set up aliases, functions, options, key bindings, etc.</description>
    </item>
    
    <item>
      <title>애드워즈 학습</title>
      <link>https://sanghunka.github.io/2018/01/%EC%95%A0%EB%93%9C%EC%9B%8C%EC%A6%88-%ED%95%99%EC%8A%B5/</link>
      <pubDate>Mon, 22 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2018/01/%EC%95%A0%EB%93%9C%EC%9B%8C%EC%A6%88-%ED%95%99%EC%8A%B5/</guid>
      <description>강의 1: 온라인 광고의 가치에 대한 이해 이 모듈에서 학습할 내용
 온라인 광고 및 애드워즈의 장점 Google의 광고 네트워크 애드워즈의 작동 원리  1.1 온라인 광고 및 애드워즈의 장점  광고 타겟팅  키워드 광고 위치 연령,위치,언어 요일,시간대,게재빈도 기기  비용관리  월, 일, 또는 광고 단위로 지출 비용 설정 가능  광고 효과 측정 캠페인 관리  MCC, 애드워즈 에디터등   애드워즈 광고
1.2 Google의 광고 네트워크  검색 네트워크</description>
    </item>
    
    <item>
      <title>Raspberrypi stretch with desktop에서 스트라티스 qt월렛 빌드하기</title>
      <link>https://sanghunka.github.io/2017/12/raspberrypi-stretch-with-desktop%EC%97%90%EC%84%9C-%EC%8A%A4%ED%8A%B8%EB%9D%BC%ED%8B%B0%EC%8A%A4-qt%EC%9B%94%EB%A0%9B-%EB%B9%8C%EB%93%9C%ED%95%98%EA%B8%B0/</link>
      <pubDate>Mon, 25 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2017/12/raspberrypi-stretch-with-desktop%EC%97%90%EC%84%9C-%EC%8A%A4%ED%8A%B8%EB%9D%BC%ED%8B%B0%EC%8A%A4-qt%EC%9B%94%EB%A0%9B-%EB%B9%8C%EB%93%9C%ED%95%98%EA%B8%B0/</guid>
      <description>&lt;p&gt;Guide대로 Jessie에서 하면 편합니다만 Stretch에서 하시길 원하신다면&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[airflow] 6. Multi cluster에서 airflow 실행하기</title>
      <link>https://sanghunka.github.io/2017/12/airflow-6.-multi-cluster%EC%97%90%EC%84%9C-airflow-%EC%8B%A4%ED%96%89%ED%95%98%EA%B8%B0/</link>
      <pubDate>Wed, 20 Dec 2017 14:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/12/airflow-6.-multi-cluster%EC%97%90%EC%84%9C-airflow-%EC%8B%A4%ED%96%89%ED%95%98%EA%B8%B0/</guid>
      <description>요약  다루는 내용  분산 인스턴스에서 각각 airflow worker를 실행하고 task를 분산해서 실행하는법 task가 실행될 worker를 명시적으로 지정하는법  테스트 환경  두 개의 Amazon EC2 Instance 사용 1번 Instance에 아래와 같이 셋팅  metadata database(postsgres) rabbitmq airflow webserver airflow worker  2번 Instance에 아래와 같이 셋팅  airflow worker    airflow configuration  1번과 2번 instance에 airflow를 설치한다. dag폴더에 동일한 파일을 넣어준다. dag폴더를 Git repository로 세팅하고 Chef, Puppet, Ansible등으로 동기화 해주는 방법도 있다.</description>
    </item>
    
    <item>
      <title>[airflow] 5. Pyspark sample code on airflow</title>
      <link>https://sanghunka.github.io/2017/12/airflow-5.-pyspark-sample-code-on-airflow/</link>
      <pubDate>Wed, 20 Dec 2017 13:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/12/airflow-5.-pyspark-sample-code-on-airflow/</guid>
      <description>&lt;p&gt;Airflow에서 Pyspark task 실행하기&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[airflow] 5. Pyspark sample code on airflow</title>
      <link>https://sanghunka.github.io/2017/12/airflow-5.-pyspark-sample-code-on-airflow/</link>
      <pubDate>Wed, 20 Dec 2017 13:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/12/airflow-5.-pyspark-sample-code-on-airflow/</guid>
      <description>&lt;p&gt;Airflow에서 Pyspark task 실행하기&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Mac] ijavascript 설치</title>
      <link>https://sanghunka.github.io/2017/12/mac-ijavascript-%EC%84%A4%EC%B9%98/</link>
      <pubDate>Wed, 20 Dec 2017 12:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/12/mac-ijavascript-%EC%84%A4%EC%B9%98/</guid>
      <description> ruby -e &amp;quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&amp;quot; brew install pkg-config node zeromq sudo easy_install pip sudo pip install --upgrade pyzmq jupyter sudo npm install -g ijavascript   설치하고자 하는 가상환경에서 ijsinstall ijsnotebook으로 실행 </description>
    </item>
    
    <item>
      <title>[airflow] 4. CeleryExecutor 사용하기</title>
      <link>https://sanghunka.github.io/2017/12/airflow-4.-celeryexecutor-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/</link>
      <pubDate>Tue, 05 Dec 2017 17:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/12/airflow-4.-celeryexecutor-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/</guid>
      <description>&lt;p&gt;Airflow CeleryExecutor 사용하기&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[airflow] 3. LocalExecutor 사용하기</title>
      <link>https://sanghunka.github.io/2017/12/airflow-3.-localexecutor-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/</link>
      <pubDate>Tue, 05 Dec 2017 16:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/12/airflow-3.-localexecutor-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/</guid>
      <description>&lt;p&gt;Airflow LocalExecutor 사용하기&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[Mac] Apche Spark 설치</title>
      <link>https://sanghunka.github.io/2017/12/mac-apche-spark-%EC%84%A4%EC%B9%98/</link>
      <pubDate>Tue, 05 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2017/12/mac-apche-spark-%EC%84%A4%EC%B9%98/</guid>
      <description>Java 설치  이미 설치된 java의 경로를 찾고 싶다면 /usr/libexec/java_home 명령어를 이용하면 된다.
 brew tap caskroom/versions brew cask search java # brew cask install java 이렇게하면 자바9가 설치됩니다. brew cask install java8   2017-12-05 현재 Spark는 Java9를 지원하지 않는다. 그러므로 java8을 설치해야한다. 아래처럼 본인의 version에 맞는 path를 .bashrc(또는 .zshrc)에 지정해준다. export JAVA_HOME=&amp;quot;/Library/Java/JavaVirtualMachines/jdk1.8.0_152.jdk/Contents/Home&amp;quot;  Scala 설치 brew install scala   java와 마찬가지로 본인의 version에 맞는 path를 .bashrc(또는 .</description>
    </item>
    
    <item>
      <title>[Mac] pymssql 설치 에러날경우</title>
      <link>https://sanghunka.github.io/2017/12/mac-pymssql-%EC%84%A4%EC%B9%98-%EC%97%90%EB%9F%AC%EB%82%A0%EA%B2%BD%EC%9A%B0/</link>
      <pubDate>Tue, 05 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2017/12/mac-pymssql-%EC%84%A4%EC%B9%98-%EC%97%90%EB%9F%AC%EB%82%A0%EA%B2%BD%EC%9A%B0/</guid>
      <description> Mac에서 pymssql 설치시 에러가 나는경우 아래와 같은 방법을 시도해보자.  # 이미 freedts가 설치되어있다면 삭제해준다. # brew uninstall freedts brew install freetds091 brew link --force freetds@0.91 pip install pymssql </description>
    </item>
    
    <item>
      <title>MaxOS Hadoop 설치</title>
      <link>https://sanghunka.github.io/2017/12/maxos-hadoop-%EC%84%A4%EC%B9%98/</link>
      <pubDate>Sat, 02 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2017/12/maxos-hadoop-%EC%84%A4%EC%B9%98/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;2.7.3기준으로 작성되어있음.&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>MaxOS Hive 설치</title>
      <link>https://sanghunka.github.io/2017/12/maxos-hive-%EC%84%A4%EC%B9%98/</link>
      <pubDate>Sat, 02 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2017/12/maxos-hive-%EC%84%A4%EC%B9%98/</guid>
      <description>참조  https://cwiki.apache.org/confluence/display/Hive/GettingStarted https://noobergeek.wordpress.com/2013/11/09/simplest-way-to-install-and-configure-hive-for-mac-osx-lion/  1. Install hive via brew. This will take some time brew install hive  2. Add hadoop and hive to your path by editing your bash_profile  zshell사용자라면 .bash_profile대신 .zshrc vi ~/.bash_profile 아래 내용 추가 bash export HADOOP_HOME=/usr/local/Cellar/hadoop/hadoop.version.no export HIVE_HOME=/usr/local/Cellar/hive/hive.version.no/libexec  source ~/.bash_profile  3. Download the mysql connector  버전은 최신버전으로 다운받으면 좋음. ``` $ curl -L &amp;lsquo;http://www.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.22.tar.gz/from/http://mysql.he.net/&#39; | tar xz  $ sudo cp mysql-connector-java-5.</description>
    </item>
    
    <item>
      <title>MaxOS Hue 설치</title>
      <link>https://sanghunka.github.io/2017/12/maxos-hue-%EC%84%A4%EC%B9%98/</link>
      <pubDate>Sat, 02 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2017/12/maxos-hue-%EC%84%A4%EC%B9%98/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;메뉴얼이 잘 되어있습니다.&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>[python]cat을 이용해서 stdin 인풋 주기</title>
      <link>https://sanghunka.github.io/2017/12/pythoncat%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%B4%EC%84%9C-stdin-%EC%9D%B8%ED%92%8B-%EC%A3%BC%EA%B8%B0/</link>
      <pubDate>Sat, 02 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2017/12/pythoncat%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%B4%EC%84%9C-stdin-%EC%9D%B8%ED%92%8B-%EC%A3%BC%EA%B8%B0/</guid>
      <description>&lt;p&gt;&lt;code&gt;cat iris.txt | python test.py&lt;/code&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[python]nbviewer 실행시키기</title>
      <link>https://sanghunka.github.io/2017/12/pythonnbviewer-%EC%8B%A4%ED%96%89%EC%8B%9C%ED%82%A4%EA%B8%B0/</link>
      <pubDate>Sat, 02 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2017/12/pythonnbviewer-%EC%8B%A4%ED%96%89%EC%8B%9C%ED%82%A4%EA%B8%B0/</guid>
      <description>&lt;p&gt;&lt;code&gt;cat iris.txt | python test.py&lt;/code&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[airflow] 2. 튜토리얼</title>
      <link>https://sanghunka.github.io/2017/11/airflow-2.-%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC/</link>
      <pubDate>Tue, 21 Nov 2017 17:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/11/airflow-2.-%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC/</guid>
      <description>&lt;p&gt;pipeline을 따라 만들어보며 Airflow의 concept, object, usage를 습득하기.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[airflow] 1. 설치</title>
      <link>https://sanghunka.github.io/2017/11/airflow-1.-%EC%84%A4%EC%B9%98/</link>
      <pubDate>Tue, 21 Nov 2017 16:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/11/airflow-1.-%EC%84%A4%EC%B9%98/</guid>
      <description>&lt;p&gt;Airflow 설치하기&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[airflow] 0. Quickstart</title>
      <link>https://sanghunka.github.io/2017/11/airflow-0.-quickstart/</link>
      <pubDate>Tue, 21 Nov 2017 15:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/11/airflow-0.-quickstart/</guid>
      <description># airflow needs a home, ~/airflow is the default, # but you can lay foundation somewhere else if you prefer # (optional) export AIRFLOW_HOME=~/airflow # install from pypi using pip pip install airflow # initialize the database airflow initdb # start the web server, default port is 8080 airflow webserver -p 8080   export AIRFLOW_HOME=~/airflow 명령어로 설치 경로를 지정할 수 있다. AIRFLOW_HOME을 지정하지 않을 경우 default 경로는 ~/airflow 설치는 pip로 간단하게 할 수 있다.</description>
    </item>
    
    <item>
      <title>[Intro to Hadoop and MapReduce] Lesson 5 MapReduce Code</title>
      <link>https://sanghunka.github.io/2017/11/intro-to-hadoop-and-mapreduce-lesson-5-mapreduce-code/</link>
      <pubDate>Mon, 06 Nov 2017 13:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/11/intro-to-hadoop-and-mapreduce-lesson-5-mapreduce-code/</guid>
      <description>1. Introduction 2. Quiz: Input Data How to find total sales/store?
 KEY VALUE  time store name cost store name store name cost store name product type  3. Quiz: Defensive Mapper Code # Your task is to make sure that this mapper code does not fail on corrupt data lines, # but instead just ignores them and continues working import sys def mapper(): # read standard input line by line for line in sys.</description>
    </item>
    
    <item>
      <title>[Intro to Hadoop and MapReduce] Lesson 4 Problem set</title>
      <link>https://sanghunka.github.io/2017/11/intro-to-hadoop-and-mapreduce-lesson-4-problem-set/</link>
      <pubDate>Mon, 06 Nov 2017 12:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/11/intro-to-hadoop-and-mapreduce-lesson-4-problem-set/</guid>
      <description>1. Quiz: HDFS Which of the following is true?
HDFS uses a central SAN(storage area network) to hold its data HDFS stores a single copy of all data HDFS replicates all data for reliability To store 100TB of data in a Hadoop cluster you would need 300TB of raw disk space by default  2. Quiz: DataNode Which of the following is true if one of the nodes running the DataNode daemon on the cluster fails?</description>
    </item>
    
    <item>
      <title>[Intro to Hadoop and MapReduce] Lesson 3 HDFS and MapReduce</title>
      <link>https://sanghunka.github.io/2017/11/intro-to-hadoop-and-mapreduce-lesson-3-hdfs-and-mapreduce/</link>
      <pubDate>Mon, 06 Nov 2017 11:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/11/intro-to-hadoop-and-mapreduce-lesson-3-hdfs-and-mapreduce/</guid>
      <description>1. Quiz: HDFS Is there a problem? &amp;gt; https://youtu.be/6F8-cCUbRU8
Network failure Disk failure on DN(datanode) Not all DN used Block sizes differ Disk failure on NN(namenode)  2. Quiz: Data Redundancy Any problem now?(when NN failure)
Data inaccessible &amp;gt; when network failure on NN Data lost forever &amp;gt; when disk failure on NN No problem  3. NameNode Standby The active namenode works before, but the standby can be configured to take over if the active one fails.</description>
    </item>
    
    <item>
      <title>[Intro to Hadoop and MapReduce] Lesson 2 Problem set</title>
      <link>https://sanghunka.github.io/2017/11/intro-to-hadoop-and-mapreduce-lesson-2-problem-set/</link>
      <pubDate>Mon, 06 Nov 2017 10:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/11/intro-to-hadoop-and-mapreduce-lesson-2-problem-set/</guid>
      <description>1. Quiz: Dimensions of Big Data Which of the following are Part of the 3 dimensions of Big Data?
Volume Cost Importance Velocity Source Variety Security Virality  2. Quiz: Volume Volume of Big Data refers to:
Importance of Data Size of data Speed of data generation The differnet data sources  3. Quiz: Hadoop Ecosystem Check all that are true:
Hadoop provides an efficient way of storing data via HDFS Hadoop has a visualization framework called &amp;lsquo;Giraffe&amp;rsquo; You can analyze large datasets using a high-level language called &amp;lsquo;Pig&amp;rsquo; &amp;lsquo;Hive&amp;rsquo; offers a SQL-like language on top of MapReduce The tools in Hadoop&amp;rsquo;s ecosystem are all proprietary, commercial tools  4.</description>
    </item>
    
    <item>
      <title>[Intro to Hadoop and MapReduce] Lesson 1 Big data</title>
      <link>https://sanghunka.github.io/2017/11/intro-to-hadoop-and-mapreduce-lesson-1-big-data/</link>
      <pubDate>Mon, 06 Nov 2017 09:00:00 +0900</pubDate>
      
      <guid>https://sanghunka.github.io/2017/11/intro-to-hadoop-and-mapreduce-lesson-1-big-data/</guid>
      <description>1. Introduction You can read more about Big Data in Wikipedia which is also a company that generates and processes huge amounts of data itself.
MapReduce and Apache Hadoop are the technologies we will be talking about more in this course.
2. Data Sources According to IBM: &amp;ldquo;Every day, 2.5 billion gigabytes of high-velocity data are created in a variety of forms, such as social media posts, information gathered in sensors and medical devices, videos and transaction records&amp;rdquo;</description>
    </item>
    
    <item>
      <title>Contents is King by Bill Gates 전문 번역</title>
      <link>https://sanghunka.github.io/2017/07/contents-is-king-by-bill-gates-%EC%A0%84%EB%AC%B8-%EB%B2%88%EC%97%AD/</link>
      <pubDate>Sun, 09 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2017/07/contents-is-king-by-bill-gates-%EC%A0%84%EB%AC%B8-%EB%B2%88%EC%97%AD/</guid>
      <description>&lt;p&gt;1996년 1월 3일에 쓰여진 글입니다.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>github.io 블로그를 만들어 보자</title>
      <link>https://sanghunka.github.io/2017/05/github.io-%EB%B8%94%EB%A1%9C%EA%B7%B8%EB%A5%BC-%EB%A7%8C%EB%93%A4%EC%96%B4-%EB%B3%B4%EC%9E%90/</link>
      <pubDate>Tue, 09 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2017/05/github.io-%EB%B8%94%EB%A1%9C%EA%B7%B8%EB%A5%BC-%EB%A7%8C%EB%93%A4%EC%96%B4-%EB%B3%B4%EC%9E%90/</guid>
      <description>github page는 무엇인가? https://pages.github.com/ 는 깃허브에서 다이렉트로 호스팅해주는 서비스이다. 무료이다. 단 깃허브 계정 하나에 한 페이지만 만들 수 있다. 개발자들은 주로 포트폴리오나 cv, 또는 개인 블로그로 사용하고있다. 내 블로그인 sanghun.xyz도 깃허브 리포지터리를 이용한 페이지이다. 도메인은 aws에서 구매해 연결했다.
참조 나는 codecademy의 deploy-a-website를 따라해서 만들었다. 쉽고 친절한 수업이라 따라만 해도 쉽게 웹사이트를 배포할 수 있다. 물론 배포까지만! 그 다음은 개인의 웹개발 역량에 달려있다. 나는 괜찮아보이는 공개 theme를 가져다 썼다. 아래의 방법은 codecademy의 수업을 요약한 것이다.</description>
    </item>
    
    <item>
      <title>stratis wallet backup하기</title>
      <link>https://sanghunka.github.io/2017/05/stratis-wallet-backup%ED%95%98%EA%B8%B0/</link>
      <pubDate>Tue, 09 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2017/05/stratis-wallet-backup%ED%95%98%EA%B8%B0/</guid>
      <description>안녕하세요.
지난글에서 지갑을 무사히 설치했다면 이번글에선 지갑을 백업하는법을 알아보겠습니다.
지갑을 무사히 설치하였더라도, 만일의 사태는 발생할 수 있습니다. 지갑이 설치된 컴퓨터가 파손된다면 어떻게 할건가요?
이럴때를 대비해 지갑을 백업해둬야만 합니다. 관리부주의로 가상화폐의 소유권을 잃어버릴수도 있습니다. 이 글을 읽으시는 분들도 반드시 백업파일을 만들어두시길 바랍니다.
백업방법 1 - 간단하게 파일 -&amp;gt; 지갑 백업을 통해 백업 파일을 만들 수 있습니다.
- 원하는 경로에 원하는 이름으로 백업 파일을 만들수 있습니다. - 이름은 원하는대로 설정 가능하지만 일반적으로는 wallet으로 하는걸 추천드립니다.</description>
    </item>
    
    <item>
      <title>스트라티스 qt월렛 리눅스에서 빌드하기</title>
      <link>https://sanghunka.github.io/2017/05/%EC%8A%A4%ED%8A%B8%EB%9D%BC%ED%8B%B0%EC%8A%A4-qt%EC%9B%94%EB%A0%9B-%EB%A6%AC%EB%88%85%EC%8A%A4%EC%97%90%EC%84%9C-%EB%B9%8C%EB%93%9C%ED%95%98%EA%B8%B0/</link>
      <pubDate>Tue, 09 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2017/05/%EC%8A%A4%ED%8A%B8%EB%9D%BC%ED%8B%B0%EC%8A%A4-qt%EC%9B%94%EB%A0%9B-%EB%A6%AC%EB%88%85%EC%8A%A4%EC%97%90%EC%84%9C-%EB%B9%8C%EB%93%9C%ED%95%98%EA%B8%B0/</guid>
      <description>&lt;p&gt;코인을 거래소에 두는건 위험합니다. 해커들이 호시탐탐 노리고있으며 거래소가 먹튀할 확률도 있습니다.
소중한 스트라티스를 개인지갑에 소중히 보관하고자 하는 취지에서 이번글을 작성해 봅니다.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>OTP앱 Authy</title>
      <link>https://sanghunka.github.io/2017/05/otp%EC%95%B1-authy/</link>
      <pubDate>Mon, 08 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2017/05/otp%EC%95%B1-authy/</guid>
      <description>&lt;p&gt;안녕하세요. 이번글에선 OTP앱인 Authy를 소개드리고자 합니다.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>appsflyer pull api를 이용해 daily report 적재하기</title>
      <link>https://sanghunka.github.io/2017/02/appsflyer-pull-api%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%B4-daily-report-%EC%A0%81%EC%9E%AC%ED%95%98%EA%B8%B0/</link>
      <pubDate>Thu, 09 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2017/02/appsflyer-pull-api%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%B4-daily-report-%EC%A0%81%EC%9E%AC%ED%95%98%EA%B8%B0/</guid>
      <description>참조: appsflyer pull api 가이드
 push api가 아닌 pull api를 사용하는 이유.
 앱스플라이어 이벤트를 많이 정의할수록 push api가 빈번하게 호출된다. 이는 서비스 품질 저하로 이어질 수 있음. (완벽한 분석용 DB가 따로 구축되어 있다면 상관 없다.) 그러므로 실시간 데이터 적재보다는 하루에 한번, 전일자 데이터를 적재하기로 결정했고 이런 용도에는 pull api가 적합하다.  product와 archive에 동시에 적재하는 이유.
 앱스플라이어에서 데이터를 무한정 제공하진 않는다. 가입한 플랜에 따라 최근 x일자 데이터만 조회가 가능하다.</description>
    </item>
    
    <item>
      <title>appsflyer pull api를 이용해 raw data 적재하기</title>
      <link>https://sanghunka.github.io/2017/02/appsflyer-pull-api%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%B4-raw-data-%EC%A0%81%EC%9E%AC%ED%95%98%EA%B8%B0/</link>
      <pubDate>Thu, 09 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2017/02/appsflyer-pull-api%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%B4-raw-data-%EC%A0%81%EC%9E%AC%ED%95%98%EA%B8%B0/</guid>
      <description>참조: appsflyer pull api 가이드
 push api가 아닌 pull api를 사용하는 이유.
 앱스플라이어 이벤트를 많이 정의할수록 push api가 빈번하게 호출된다. 이는 서비스 품질 저하로 이어질 수 있음. (완벽한 분석용 DB가 따로 구축되어 있다면 상관 없다.) 그러므로 실시간 데이터 적재보다는 하루에 한번, 전일자 데이터를 적재하기로 결정했고 이런 용도에는 pull api가 적합하다.  product와 archive에 동시에 적재하는 이유.
 앱스플라이어에서 데이터를 무한정 제공하진 않는다. 가입한 플랜에 따라 최근 x일자 데이터만 조회가 가능하다.</description>
    </item>
    
    <item>
      <title>apache zeppelin에 postgres DB 연결하기</title>
      <link>https://sanghunka.github.io/2017/01/apache-zeppelin%EC%97%90-postgres-db-%EC%97%B0%EA%B2%B0%ED%95%98%EA%B8%B0/</link>
      <pubDate>Mon, 23 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2017/01/apache-zeppelin%EC%97%90-postgres-db-%EC%97%B0%EA%B2%B0%ED%95%98%EA%B8%B0/</guid>
      <description>
 제플린 빌드 후 오른쪽 상단에서 Interpreter 클릭  
 jdbc에서 DB 정보 입력
 common.max_count: 한번에 몇개의 row를 조회할 것인지 설정
 default.driver: org.postgresql.Driver
 default.password: DB 패스워드
 default.url: DB 주소. jdbc:postgresql://DNS_ADDRESS:PORT/DBNAME 형태로 입력.
 default.user: DB user name 입력
  
 notebook에서 첫줄에 %jdbc입력 후 테스트 쿼리를 날려보면 잘 되는걸 확인 할 수 있다. </description>
    </item>
    
    <item>
      <title>apache zeppelin의 dynamic form 정리</title>
      <link>https://sanghunka.github.io/2017/01/apache-zeppelin%EC%9D%98-dynamic-form-%EC%A0%95%EB%A6%AC/</link>
      <pubDate>Mon, 23 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2017/01/apache-zeppelin%EC%9D%98-dynamic-form-%EC%A0%95%EB%A6%AC/</guid>
      <description>&lt;p&gt;dynamic form을 이용하면 충분히 쓸만한 custom dashboard를 만들 수 있다.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>macOS Sierra에서 virtualenv에 Opencv3 설치</title>
      <link>https://sanghunka.github.io/2016/12/macos-sierra%EC%97%90%EC%84%9C-virtualenv%EC%97%90-opencv3-%EC%84%A4%EC%B9%98/</link>
      <pubDate>Tue, 06 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2016/12/macos-sierra%EC%97%90%EC%84%9C-virtualenv%EC%97%90-opencv3-%EC%84%A4%EC%B9%98/</guid>
      <description>python3 설치  간단하게 brew로 설치하자  brew install python3  opencv3 설치  3은 아직 베타라고 한다. 안전한 버전을 원하면 opencv2를 설치하자. 나는 그냥 3설치 했다.  brew tap homebrew/science brew install opencv3 --with-python3 --with-ffmpeg --with-tbb --with-contrib  2016.12.04 임시 설치법  현재 mac OS Sierra에서 Opencv 설치에 문제가 있다. &amp;ndash;HEAD를 추가해 아래 방법대로 하면 된다. (16.12.4 기준) https://github.com/Homebrew/homebrew-science/issues/4104#issuecomment-249362870  brew install opencv3 --HEAD --with-python3 --with-ffmpeg --with-tbb --with-contrib  lookup 만들어주기  Ln -s {opencv의 site-packages} {사용하는 python환경의 site-packages} 형태로 lookup을 만들어 준다.</description>
    </item>
    
    <item>
      <title>jekyll github blog gemfile 버전 에러</title>
      <link>https://sanghunka.github.io/2016/11/jekyll-github-blog-gemfile-%EB%B2%84%EC%A0%84-%EC%97%90%EB%9F%AC/</link>
      <pubDate>Mon, 21 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2016/11/jekyll-github-blog-gemfile-%EB%B2%84%EC%A0%84-%EC%97%90%EB%9F%AC/</guid>
      <description>&lt;p&gt;이런 에러가 났다. config파일을 바꿔보고 루비와 jekyll을 지웠다 다시 깔아보고 했지만 모두 실패함.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>python에서 postgres DB 연결해서 쿼리 조회하기</title>
      <link>https://sanghunka.github.io/2016/11/python%EC%97%90%EC%84%9C-postgres-db-%EC%97%B0%EA%B2%B0%ED%95%B4%EC%84%9C-%EC%BF%BC%EB%A6%AC-%EC%A1%B0%ED%9A%8C%ED%95%98%EA%B8%B0/</link>
      <pubDate>Mon, 21 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2016/11/python%EC%97%90%EC%84%9C-postgres-db-%EC%97%B0%EA%B2%B0%ED%95%B4%EC%84%9C-%EC%BF%BC%EB%A6%AC-%EC%A1%B0%ED%9A%8C%ED%95%98%EA%B8%B0/</guid>
      <description>&lt;p&gt;2번 방법을 추천한다. 이유는 아래에서.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Welcome to Tranquilpeak 0.4.2-BETA</title>
      <link>https://sanghunka.github.io/2015/06/welcome-to-tranquilpeak-0.4.2-beta/</link>
      <pubDate>Mon, 15 Jun 2015 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2015/06/welcome-to-tranquilpeak-0.4.2-beta/</guid>
      <description>&lt;p&gt;Tranquilpeak is a gorgeous responsive theme for Hugo blog framework. It has many features and integrated services to improve user experience.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Elements showcase</title>
      <link>https://sanghunka.github.io/2015/05/elements-showcase/</link>
      <pubDate>Thu, 28 May 2015 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2015/05/elements-showcase/</guid>
      <description>&lt;p&gt;Check out how Tranquilpeak theme display well HTML elements (title, paragraph, blockquote, table and more..). It&amp;rsquo;s simple and elegant.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Cover image showcase</title>
      <link>https://sanghunka.github.io/2015/05/cover-image-showcase/</link>
      <pubDate>Wed, 13 May 2015 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2015/05/cover-image-showcase/</guid>
      <description>&lt;p&gt;Tranquilpeak integrate a unique &amp;ldquo;cover image&amp;rdquo; feature. Open this post to see how this feature sublimate your article.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>highlighted code showcase</title>
      <link>https://sanghunka.github.io/2015/03/highlighted-code-showcase/</link>
      <pubDate>Mon, 23 Mar 2015 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2015/03/highlighted-code-showcase/</guid>
      <description>&lt;p&gt;Tranquilpeak Hugo theme have its own theme to highlight source code. It&amp;rsquo;s based on GitHub theme: simple and elegant. Check out how it sublimate source codes.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Tags plugins showcase</title>
      <link>https://sanghunka.github.io/2014/10/tags-plugins-showcase/</link>
      <pubDate>Wed, 29 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2014/10/tags-plugins-showcase/</guid>
      <description>&lt;p&gt;This post is used to show how tag plugins are displayed. See &lt;a href=&#34;https://github.com/kakawait/hugo-tranquilpeak-theme/blob/master/docs/user.md#tags&#34;&gt;docs&lt;/a&gt; for more info.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Hidden social section showcase</title>
      <link>https://sanghunka.github.io/2014/08/hidden-social-section-showcase/</link>
      <pubDate>Sun, 17 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2014/08/hidden-social-section-showcase/</guid>
      <description>&lt;p&gt;This post is used to show how a site looks if the social section is hidden.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Hidden tag section showcase</title>
      <link>https://sanghunka.github.io/2014/08/hidden-tag-section-showcase/</link>
      <pubDate>Sat, 16 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2014/08/hidden-tag-section-showcase/</guid>
      <description>&lt;p&gt;This post is used to show how a site looks if the tag section is hidden.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Hidden pagination showcase</title>
      <link>https://sanghunka.github.io/2014/08/hidden-pagination-showcase/</link>
      <pubDate>Fri, 15 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2014/08/hidden-pagination-showcase/</guid>
      <description>&lt;p&gt;This post is used to show how a site looks if the pagination is hidden.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Video integrations showcase</title>
      <link>https://sanghunka.github.io/2014/08/video-integrations-showcase/</link>
      <pubDate>Sat, 09 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2014/08/video-integrations-showcase/</guid>
      <description>&lt;p&gt;Youtube and Vimeo videos are easily integrated thanks to tags plugins. Of course, you can add video other platforms like dailymotion.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Image gallery showcase</title>
      <link>https://sanghunka.github.io/2013/02/image-gallery-showcase/</link>
      <pubDate>Mon, 18 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/2013/02/image-gallery-showcase/</guid>
      <description>&lt;p&gt;And here is the image gallery!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sanghunka.github.io/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/1/01/</guid>
      <description>Install the RabbitMQ Server  http://www.rabbitmq.com/install-homebrew.html brew install rabbitmq  Run RabbitMQ Server path 설정  PATH=$PATH:/usr/local/sbin to your .bash_profile  실행  rabbitmq-server 기본 credential user명: guest, password: guest  localhost로 연결시에만 기본 user가 사용 가능하며 다른 연결을 사용할 경우 미리 credential을 설정해야 한다.   Controlling System Limits on OS X  대부분의 OS에서, Max number of open files는 messaging broker로 쓰기엔 턱없이 적다. rabbitmq를 이용하기 위해, production에선 최소한 65536이상, 개발환경에선 4096이상의 Max number of open files를 지정해주는걸 추천.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sanghunka.github.io/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/1/01/</guid>
      <description>Docker : docker run &amp;ndash;net=host -it -p 8888:8888 image:version
docker run -i -t -p 8888:8888 sanghkaang/bootcamp:0.0.3
Container : jupyter notebook &amp;ndash;ip 0.0.0.0 &amp;ndash;no-browser
jupyter notebook &amp;ndash;ip=0.0.0.0 &amp;ndash;no-browser &amp;ndash;allow-root
Host : localhost:8888/tree‌
도커 여러 쉘 실행 docker exec -it  bash
도커 커밋하는법 docker commit 컨테이너명 이미지명 도커 push docker push sanghkaang/bootcamp:0.0.5
도커 카피 docker comp 로컬파일 컨테이너주소:</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sanghunka.github.io/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/1/01/</guid>
      <description>brew install hugo</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sanghunka.github.io/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/1/01/</guid>
      <description>펠리칸 http://nafiulis.me/making-a-static-blog-with-pelican.html
pelican-quickstart make devserver
mkdir blog cd blog pelican-quickstart git init git remote add origin https://github.com/sanghkaang/blog.git git commit -m &amp;ldquo;pelican-quickstart&amp;rdquo; 샘플 md 추가하고 메잌 퍼블리쉬 아웃풋폴ㄹ더가서 git init
git remote add origin https://github.com/sanghkaang/sanghkaang.github.io.git git commit -m &amp;ldquo;first commit&amp;rdquo; git push -u origin master &amp;mdash;&amp;mdash;레포설정완료하고 커밋까지 완료
그다음 섭모듈등록 hint: git rm &amp;ndash;cached output 폴더가 아니라파일형태로 보인다면 add하고 커미샇자
add commit push
CNAME 알아서 들어감 gui에서 설정하면
그리고 섭모듈 사용하는법</description>
    </item>
    
    <item>
      <title></title>
      <link>https://sanghunka.github.io/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://sanghunka.github.io/1/01/</guid>
      <description>rabbitmq-plugins enable rabbitmq_management sudo service rabbitmq-server start
sudo rabbitmqctl add_user rabbitmq_airflow_user rabbitmq_airflow_user sudo rabbitmqctl set_user_tags rabbitmq_airflow_user administrator sudo rabbitmqctl set_permissions -p / rabbitmq_airflow_user &amp;ldquo;.&amp;rdquo; &amp;ldquo;.&amp;rdquo; &amp;ldquo;.*&amp;rdquo; sudo rabbitmqctl add_vhost rabbitmq_airflow_vhost
ps aux|grep rabbit|awk &amp;lsquo;{print $2}&amp;rsquo; sudo kill -9 11745
rabbitmqctl add_user openstack_rabbit_user openstack_rabbit_password; rabbitmqctl set_permissions -p / openstack_rabbit_user &amp;ldquo;.&amp;rdquo; &amp;ldquo;.&amp;rdquo; &amp;ldquo;.*&amp;rdquo; ; rabbitmqctl set_user_tags openstack_rabbit_user administrator;
sudo kill ps -ef | grep airflow|awk &#39;{print $2}&#39; sudo kill ps -ef | grep rabbit|awk &#39;{print $2}&#39; sudo service postgresql restart</description>
    </item>
    
  </channel>
</rss>